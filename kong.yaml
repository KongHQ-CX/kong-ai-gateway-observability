_format_version: "3.0"

plugins:
  - name: http-log
    config:
      http_endpoint: http://logstash:8888

services:
  - name: ai
    url: https://localhost:32000

    routes:
      - name: openai-gpt4o
        paths:
          - "/gpt4o"
        plugins:
          - name: ai-proxy
            config:
              route_type: llm/v1/chat
              model:
                provider: openai
                name: gpt-4o
              auth:
                header_name: Authorization
                header_value: "{vault://env/OPENAI_API_KEY}"
              logging:
                log_statistics: true
                log_payloads: true

          # Now we add a security plugin at the "model" scope
          - name: key-auth
            config:
              key_names:
                - Authorization

# and finally a consumer with **its own API key**
consumers:
  - username: department-1
    keyauth_credentials:
      - key: "Bearer department-1-api-key"
